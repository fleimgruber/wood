<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<link href='http://fonts.googleapis.com/css?family=Arvo:400,700'
      rel='stylesheet' type='text/css'/>

<title>How much of the world is woody?</title>

<!-- Styles for R syntax highlighter -->
<style type="text/css">
   pre .operator,
   pre .paren {
     color: rgb(104, 118, 135)
   }

   pre .literal {
     color: #990073
   }

   pre .number {
     color: #099;
   }

   pre .comment {
     color: #998;
     font-style: italic
   }

   pre .keyword {
     color: #900;
     font-weight: bold
   }

   pre .identifier {
     color: rgb(0, 0, 0);
   }

   pre .string {
     color: #d14;
   }
</style>

<!-- R syntax highlighter -->
<script type="text/javascript">
var hljs=new function(){function m(p){return p.replace(/&/gm,"&amp;").replace(/</gm,"&lt;")}function f(r,q,p){return RegExp(q,"m"+(r.cI?"i":"")+(p?"g":""))}function b(r){for(var p=0;p<r.childNodes.length;p++){var q=r.childNodes[p];if(q.nodeName=="CODE"){return q}if(!(q.nodeType==3&&q.nodeValue.match(/\s+/))){break}}}function h(t,s){var p="";for(var r=0;r<t.childNodes.length;r++){if(t.childNodes[r].nodeType==3){var q=t.childNodes[r].nodeValue;if(s){q=q.replace(/\n/g,"")}p+=q}else{if(t.childNodes[r].nodeName=="BR"){p+="\n"}else{p+=h(t.childNodes[r])}}}if(/MSIE [678]/.test(navigator.userAgent)){p=p.replace(/\r/g,"\n")}return p}function a(s){var r=s.className.split(/\s+/);r=r.concat(s.parentNode.className.split(/\s+/));for(var q=0;q<r.length;q++){var p=r[q].replace(/^language-/,"");if(e[p]){return p}}}function c(q){var p=[];(function(s,t){for(var r=0;r<s.childNodes.length;r++){if(s.childNodes[r].nodeType==3){t+=s.childNodes[r].nodeValue.length}else{if(s.childNodes[r].nodeName=="BR"){t+=1}else{if(s.childNodes[r].nodeType==1){p.push({event:"start",offset:t,node:s.childNodes[r]});t=arguments.callee(s.childNodes[r],t);p.push({event:"stop",offset:t,node:s.childNodes[r]})}}}}return t})(q,0);return p}function k(y,w,x){var q=0;var z="";var s=[];function u(){if(y.length&&w.length){if(y[0].offset!=w[0].offset){return(y[0].offset<w[0].offset)?y:w}else{return w[0].event=="start"?y:w}}else{return y.length?y:w}}function t(D){var A="<"+D.nodeName.toLowerCase();for(var B=0;B<D.attributes.length;B++){var C=D.attributes[B];A+=" "+C.nodeName.toLowerCase();if(C.value!==undefined&&C.value!==false&&C.value!==null){A+='="'+m(C.value)+'"'}}return A+">"}while(y.length||w.length){var v=u().splice(0,1)[0];z+=m(x.substr(q,v.offset-q));q=v.offset;if(v.event=="start"){z+=t(v.node);s.push(v.node)}else{if(v.event=="stop"){var p,r=s.length;do{r--;p=s[r];z+=("</"+p.nodeName.toLowerCase()+">")}while(p!=v.node);s.splice(r,1);while(r<s.length){z+=t(s[r]);r++}}}}return z+m(x.substr(q))}function j(){function q(x,y,v){if(x.compiled){return}var u;var s=[];if(x.k){x.lR=f(y,x.l||hljs.IR,true);for(var w in x.k){if(!x.k.hasOwnProperty(w)){continue}if(x.k[w] instanceof Object){u=x.k[w]}else{u=x.k;w="keyword"}for(var r in u){if(!u.hasOwnProperty(r)){continue}x.k[r]=[w,u[r]];s.push(r)}}}if(!v){if(x.bWK){x.b="\\b("+s.join("|")+")\\s"}x.bR=f(y,x.b?x.b:"\\B|\\b");if(!x.e&&!x.eW){x.e="\\B|\\b"}if(x.e){x.eR=f(y,x.e)}}if(x.i){x.iR=f(y,x.i)}if(x.r===undefined){x.r=1}if(!x.c){x.c=[]}x.compiled=true;for(var t=0;t<x.c.length;t++){if(x.c[t]=="self"){x.c[t]=x}q(x.c[t],y,false)}if(x.starts){q(x.starts,y,false)}}for(var p in e){if(!e.hasOwnProperty(p)){continue}q(e[p].dM,e[p],true)}}function d(B,C){if(!j.called){j();j.called=true}function q(r,M){for(var L=0;L<M.c.length;L++){if((M.c[L].bR.exec(r)||[null])[0]==r){return M.c[L]}}}function v(L,r){if(D[L].e&&D[L].eR.test(r)){return 1}if(D[L].eW){var M=v(L-1,r);return M?M+1:0}return 0}function w(r,L){return L.i&&L.iR.test(r)}function K(N,O){var M=[];for(var L=0;L<N.c.length;L++){M.push(N.c[L].b)}var r=D.length-1;do{if(D[r].e){M.push(D[r].e)}r--}while(D[r+1].eW);if(N.i){M.push(N.i)}return f(O,M.join("|"),true)}function p(M,L){var N=D[D.length-1];if(!N.t){N.t=K(N,E)}N.t.lastIndex=L;var r=N.t.exec(M);return r?[M.substr(L,r.index-L),r[0],false]:[M.substr(L),"",true]}function z(N,r){var L=E.cI?r[0].toLowerCase():r[0];var M=N.k[L];if(M&&M instanceof Array){return M}return false}function F(L,P){L=m(L);if(!P.k){return L}var r="";var O=0;P.lR.lastIndex=0;var M=P.lR.exec(L);while(M){r+=L.substr(O,M.index-O);var N=z(P,M);if(N){x+=N[1];r+='<span class="'+N[0]+'">'+M[0]+"</span>"}else{r+=M[0]}O=P.lR.lastIndex;M=P.lR.exec(L)}return r+L.substr(O,L.length-O)}function J(L,M){if(M.sL&&e[M.sL]){var r=d(M.sL,L);x+=r.keyword_count;return r.value}else{return F(L,M)}}function I(M,r){var L=M.cN?'<span class="'+M.cN+'">':"";if(M.rB){y+=L;M.buffer=""}else{if(M.eB){y+=m(r)+L;M.buffer=""}else{y+=L;M.buffer=r}}D.push(M);A+=M.r}function G(N,M,Q){var R=D[D.length-1];if(Q){y+=J(R.buffer+N,R);return false}var P=q(M,R);if(P){y+=J(R.buffer+N,R);I(P,M);return P.rB}var L=v(D.length-1,M);if(L){var O=R.cN?"</span>":"";if(R.rE){y+=J(R.buffer+N,R)+O}else{if(R.eE){y+=J(R.buffer+N,R)+O+m(M)}else{y+=J(R.buffer+N+M,R)+O}}while(L>1){O=D[D.length-2].cN?"</span>":"";y+=O;L--;D.length--}var r=D[D.length-1];D.length--;D[D.length-1].buffer="";if(r.starts){I(r.starts,"")}return R.rE}if(w(M,R)){throw"Illegal"}}var E=e[B];var D=[E.dM];var A=0;var x=0;var y="";try{var s,u=0;E.dM.buffer="";do{s=p(C,u);var t=G(s[0],s[1],s[2]);u+=s[0].length;if(!t){u+=s[1].length}}while(!s[2]);if(D.length>1){throw"Illegal"}return{r:A,keyword_count:x,value:y}}catch(H){if(H=="Illegal"){return{r:0,keyword_count:0,value:m(C)}}else{throw H}}}function g(t){var p={keyword_count:0,r:0,value:m(t)};var r=p;for(var q in e){if(!e.hasOwnProperty(q)){continue}var s=d(q,t);s.language=q;if(s.keyword_count+s.r>r.keyword_count+r.r){r=s}if(s.keyword_count+s.r>p.keyword_count+p.r){r=p;p=s}}if(r.language){p.second_best=r}return p}function i(r,q,p){if(q){r=r.replace(/^((<[^>]+>|\t)+)/gm,function(t,w,v,u){return w.replace(/\t/g,q)})}if(p){r=r.replace(/\n/g,"<br>")}return r}function n(t,w,r){var x=h(t,r);var v=a(t);var y,s;if(v){y=d(v,x)}else{return}var q=c(t);if(q.length){s=document.createElement("pre");s.innerHTML=y.value;y.value=k(q,c(s),x)}y.value=i(y.value,w,r);var u=t.className;if(!u.match("(\\s|^)(language-)?"+v+"(\\s|$)")){u=u?(u+" "+v):v}if(/MSIE [678]/.test(navigator.userAgent)&&t.tagName=="CODE"&&t.parentNode.tagName=="PRE"){s=t.parentNode;var p=document.createElement("div");p.innerHTML="<pre><code>"+y.value+"</code></pre>";t=p.firstChild.firstChild;p.firstChild.cN=s.cN;s.parentNode.replaceChild(p.firstChild,s)}else{t.innerHTML=y.value}t.className=u;t.result={language:v,kw:y.keyword_count,re:y.r};if(y.second_best){t.second_best={language:y.second_best.language,kw:y.second_best.keyword_count,re:y.second_best.r}}}function o(){if(o.called){return}o.called=true;var r=document.getElementsByTagName("pre");for(var p=0;p<r.length;p++){var q=b(r[p]);if(q){n(q,hljs.tabReplace)}}}function l(){if(window.addEventListener){window.addEventListener("DOMContentLoaded",o,false);window.addEventListener("load",o,false)}else{if(window.attachEvent){window.attachEvent("onload",o)}else{window.onload=o}}}var e={};this.LANGUAGES=e;this.highlight=d;this.highlightAuto=g;this.fixMarkup=i;this.highlightBlock=n;this.initHighlighting=o;this.initHighlightingOnLoad=l;this.IR="[a-zA-Z][a-zA-Z0-9_]*";this.UIR="[a-zA-Z_][a-zA-Z0-9_]*";this.NR="\\b\\d+(\\.\\d+)?";this.CNR="\\b(0[xX][a-fA-F0-9]+|(\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)";this.BNR="\\b(0b[01]+)";this.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|\\.|-|-=|/|/=|:|;|<|<<|<<=|<=|=|==|===|>|>=|>>|>>=|>>>|>>>=|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~";this.ER="(?![\\s\\S])";this.BE={b:"\\\\.",r:0};this.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[this.BE],r:0};this.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[this.BE],r:0};this.CLCM={cN:"comment",b:"//",e:"$"};this.CBLCLM={cN:"comment",b:"/\\*",e:"\\*/"};this.HCM={cN:"comment",b:"#",e:"$"};this.NM={cN:"number",b:this.NR,r:0};this.CNM={cN:"number",b:this.CNR,r:0};this.BNM={cN:"number",b:this.BNR,r:0};this.inherit=function(r,s){var p={};for(var q in r){p[q]=r[q]}if(s){for(var q in s){p[q]=s[q]}}return p}}();hljs.LANGUAGES.cpp=function(){var a={keyword:{"false":1,"int":1,"float":1,"while":1,"private":1,"char":1,"catch":1,"export":1,virtual:1,operator:2,sizeof:2,dynamic_cast:2,typedef:2,const_cast:2,"const":1,struct:1,"for":1,static_cast:2,union:1,namespace:1,unsigned:1,"long":1,"throw":1,"volatile":2,"static":1,"protected":1,bool:1,template:1,mutable:1,"if":1,"public":1,friend:2,"do":1,"return":1,"goto":1,auto:1,"void":2,"enum":1,"else":1,"break":1,"new":1,extern:1,using:1,"true":1,"class":1,asm:1,"case":1,typeid:1,"short":1,reinterpret_cast:2,"default":1,"double":1,register:1,explicit:1,signed:1,typename:1,"try":1,"this":1,"switch":1,"continue":1,wchar_t:1,inline:1,"delete":1,alignof:1,char16_t:1,char32_t:1,constexpr:1,decltype:1,noexcept:1,nullptr:1,static_assert:1,thread_local:1,restrict:1,_Bool:1,complex:1},built_in:{std:1,string:1,cin:1,cout:1,cerr:1,clog:1,stringstream:1,istringstream:1,ostringstream:1,auto_ptr:1,deque:1,list:1,queue:1,stack:1,vector:1,map:1,set:1,bitset:1,multiset:1,multimap:1,unordered_set:1,unordered_map:1,unordered_multiset:1,unordered_multimap:1,array:1,shared_ptr:1}};return{dM:{k:a,i:"</",c:[hljs.CLCM,hljs.CBLCLM,hljs.QSM,{cN:"string",b:"'\\\\?.",e:"'",i:"."},{cN:"number",b:"\\b(\\d+(\\.\\d*)?|\\.\\d+)(u|U|l|L|ul|UL|f|F)"},hljs.CNM,{cN:"preprocessor",b:"#",e:"$"},{cN:"stl_container",b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:a,r:10,c:["self"]}]}}}();hljs.LANGUAGES.r={dM:{c:[hljs.HCM,{cN:"number",b:"\\b0[xX][0-9a-fA-F]+[Li]?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+(?:[eE][+\\-]?\\d*)?L\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\b\\d+\\.(?!\\d)(?:i\\b)?",e:hljs.IMMEDIATE_RE,r:1},{cN:"number",b:"\\b\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"keyword",b:"(?:tryCatch|library|setGeneric|setGroupGeneric)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\.",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\.\\.\\d+(?![\\w.])",e:hljs.IMMEDIATE_RE,r:10},{cN:"keyword",b:"\\b(?:function)",e:hljs.IMMEDIATE_RE,r:2},{cN:"keyword",b:"(?:if|in|break|next|repeat|else|for|return|switch|while|try|stop|warning|require|attach|detach|source|setMethod|setClass)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"literal",b:"(?:NA|NA_integer_|NA_real_|NA_character_|NA_complex_)\\b",e:hljs.IMMEDIATE_RE,r:10},{cN:"literal",b:"(?:NULL|TRUE|FALSE|T|F|Inf|NaN)\\b",e:hljs.IMMEDIATE_RE,r:1},{cN:"identifier",b:"[a-zA-Z.][a-zA-Z0-9._]*\\b",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"<\\-(?!\\s*\\d)",e:hljs.IMMEDIATE_RE,r:2},{cN:"operator",b:"\\->|<\\-",e:hljs.IMMEDIATE_RE,r:1},{cN:"operator",b:"%%|~",e:hljs.IMMEDIATE_RE},{cN:"operator",b:">=|<=|==|!=|\\|\\||&&|=|\\+|\\-|\\*|/|\\^|>|<|!|&|\\||\\$|:",e:hljs.IMMEDIATE_RE,r:0},{cN:"operator",b:"%",e:"%",i:"\\n",r:1},{cN:"identifier",b:"`",e:"`",r:0},{cN:"string",b:'"',e:'"',c:[hljs.BE],r:0},{cN:"string",b:"'",e:"'",c:[hljs.BE],r:0},{cN:"paren",b:"[[({\\])}]",e:hljs.IMMEDIATE_RE,r:0}]}};
hljs.initHighlightingOnLoad();
</script>

<!-- MathJax scripts -->
<script type="text/javascript" src="https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<style type="text/css">
/* http://colorschemedesigner.com/#0A61P----SjTe */

html, body {
   margin:0;
   padding:0;
   height:100%;

   margin: auto;

   line-height: 1.8em;
   background-color: #ffeeca;
   /*color: ;*/
   font-family: Arvo, sans-serif;
}

#container {
    margin: 0 auto;
    padding-bottom: 3em;

    width: 80%;
    max-width: 80em;

    min-height:100%;
    position:relative;
}

#container-front {
    min-height:100%;
    position:relative;
}

/* Body for most pages */
#body {
    max-width: 60em; /* 960px */
    position: relative;
    background: white;
    /*margin: 40px 0 0 0; */
    padding: 2em 4em 3em 2em;
    /* Curvy outside */
    border-radius:         10px;
    /* Shadow */
    box-shadow:         0 6px 10px rgba(0, 0, 0, 0.5);
}

/* Front page */
#body-front {
    padding:10px;
    /*padding-bottom: 40px;   /* Height of the footer */
    width: 800px;
}

#header {
    padding:10px;
}

#lhs {
    /* border: solid red;  /* debug */
    /* Positioning */
    display: inline-block;
    position: relative;
    left: 60px;
    float: left;

    /* Size and margins */
    width: 340px;
    margin-top: 30px;
    margin-left: 10px;
    margin-right: 10px;
    padding: 30px;

    /* Fonts and colours */
    font-size: 110%;
    background-color: white;

    /* Other */
    border-radius: 10px;
    box-shadow:    0 6px 10px rgba(0, 0, 0, 0.5);
}

#rhs { 
    /* border: solid blue; /* debug */ 

    /* Positioning */
    display: inline-block;
    position: relative;
    left: 60px;
    float: left;

    /* Size and margins */
    width: 340px;
    margin-top: 30px;
    margin-left: 10px;
    margin-right: 10px;
    margin-bottom: 0px;
    padding: 0px;
    padding-top: 30px;

    /* Fonts and colours */
    font-size: 100%;
    background-color: #ffeeca66;
    /*line-height: 1.8em;*/
    outline-color: #586E75;
    outline-style: none;
    outline-width: 0px;

    box-shadow:    10px 20px 20px #ffeeca66; /*rgba(255, 238, 202, 1);*/

    /* Other */
    zoom: 1;
}

#lhs p {
    margin-top: 0px;
}
#lhs p:last-child {margin-bottom: 0px;}

#rhs ul {
    margin-top: 0px;
    list-style-type: none;
    padding-left: 0px;
}

#rhs li {
    margin-bottom: 1ex;
    
}

::selection {
    background: #00BFFF;
    color: white;
    text-shadow: none;
}

.name {
    color: #FF3900;
    font-weight: bold;
    font-size: 120%;
    text-decoration: none;
    border: none;
}

a:visited {
    color: #FF8300;
}
a, a:active {
    color: #FF8300;
    vertical-align: baseline;
    text-decoration: none;
    border-bottom: 1px dotted #B58900;
}

a:hover {
    color: #036;
}

#footer {
    position:absolute;
    bottom:0;
    width:100%;
    height:10px;   /* Height of the footer */
    background:#000;
    padding-top: 5px;
    opacity: .3;
    -webkit-transition-duration: 0.2s;
    /*-webkit-transition-timing-function: ease;*/
/*padding-top: 5px;*/
}

p.icons {
    padding: 0;
}

p.icons a {
    color: #FF3900;
    border: none;
    padding: 0;
}

p.ref, p.paperinfo {
    font-size: 90%;
    margin: 0;
    padding: 0;
    padding-left: 2em;
}

p.ref {
    color: #777777;
}

p.paperinfo a {
    white-space: nowrap;
}

.lowerright {
    position:absolute;
    bottom:0;
    right:0;
}

#footer:Hover {
    opacity: 1;
    height: 36px;
}
#footer img {
    padding-left: .5em;
}

#footer a {
    text-decoration: none;
    border: 0;
}

hr.eop {
    border: 0;
    border-bottom: 1px solid black;
    margin-left: 2em;
    margin-right: 2em;
    margin-top: 1em;
    margin-bottom: 0.5em;
}

#bottom-nav {
    float: left;
    font-size: 80%;
}

h1{
    color: #FF3900;
}

h2 {
    color: #FF8300;
    font-size: 110%;
}

/* Extra things for R code */
pre, img {
  max-width: 100%;
}

pre code {
   display: block; 
   line-height: 20px;
   padding: 0.5em;
}

code {
  font-size: 92%;
  background: #fff8ea;
}
</style>



</head>

<body>
  <div id="container">
    <div id="header"></div>
    <div id="body">
<h1>How much of the world is woody?</h1>

<p><a href="http://www.zoology.ubc.ca/%7Efitzjohn">Richard G. FitzJohn</a>,
<a href="http://mwpennell.wordpress.com">Matthew W. Pennell</a>,
<a href="http://phylodiversity.net/azanne/">Amy E. Zanne</a>,
<a href="http://www.missouribotanicalgarden.org/plant-scence/research-staff-article/487/stevens-p-f.aspx">Peter F. Stevens</a>,
<a href="http://www.phylodiversity.net/dtank/">David C. Tank</a>, 
<a href="http://www.phylodiversity.net/wcornwell/">William K. Cornwell</a></p>

<p>This is the full analysis that underlies our paper.    </p>

<h1>Preliminaries</h1>

<p>Ensure that you have all the required packages installed by running</p>

<pre><code>make deps
</code></pre>

<p>Before running this script, be sure to have the required data in
place.  If you have <code>make</code> installed, this can be done by running</p>

<pre><code>make data-processed
</code></pre>

<p>at the command line.  See <code>README.md</code> for more details.</p>

<p>See the file <code>data/README.md</code> for more information about the data
that we use, and alternative ways of running things if you don&#39;t
have <code>make</code> installed.</p>

<pre><code class="r">library(diversitree)
</code></pre>

<pre><code>## Loading required package: deSolve
## Loading required package: ape
## Loading required package: subplex
## Loading required package: Rcpp
</code></pre>

<pre><code class="r">source(&quot;R/load.R&quot;)
source(&quot;R/util.R&quot;)
</code></pre>

<p>Colours used throughout:</p>

<pre><code class="r">cols.methods &lt;- c(binomial=&quot;#a63813&quot;,
                  hypergeometric=&quot;#4d697f&quot;)
cols.tree &lt;- c(Monilophytes=&quot;#a63813&quot;,
               Gymnosperms=&quot;#21313b&quot;,
               BasalAngiosperms=&quot;#eeb911&quot;,
               Monocots=&quot;#204d14&quot;,
               Eudicots=&quot;#4d697f&quot;,
               Rest=&quot;gray15&quot;)
cols.woody &lt;- c(Woody=&quot;#533d0c&quot;,
                Herbaceous=&quot;#799321&quot;)
cols.woody &lt;- c(Woody=&quot;black&quot;,
                Herbaceous=&quot;white&quot;)
cols.shading &lt;- &quot;#eeb911&quot;
cols.tropical &lt;- c(tropical=&quot;#ea7518&quot;,
                   temperate=&quot;#62a184&quot;)
</code></pre>

<p>The &#39;load.woodiness.data.genus&#39; function hides a reasonable amount
of data cleaning required to load the data.  This mostly involves
matching the woodiness data set from Zanne et al. to our species
list (derived from The Plant List), cleaning up synonomies, and
then collapsing down to genus.</p>

<p>The final object has columns</p>

<ul>
<li>genus, family, order &ndash; taxonomic information</li>
<li>W, V, H              &ndash; number of species scored as woody,
                      variable, herbaceous (respectively)</li>
<li>N                    &ndash; number of species in the genus</li>
<li>K                    &ndash; number of species with known state,
                      after dropping all &ldquo;variable&rdquo; species</li>
<li>p                    &ndash; fraction of known species that are woody,
                      after dropping all &ldquo;variable&rdquo; species</li>
</ul>

<pre><code class="r">dat.g &lt;- load.woodiness.genus()
</code></pre>

<h1>Imputing the state of missing species</h1>

<p>For each genus:</p>

<p>A. If the genus has a valid fraction of species (i.e. K &gt; 0 so p is
defined), then sample the number of species that are woody from
either</p>

<ul>
<li>the binomial distribution (strong prior; assuming known
 species were sampled with replacement from the pool of
 species); or</li>
<li>the hypergeometric distribution (weak prior; assuming that
 known species were sampled without replacement from the pool
 of species).</li>
</ul>

<p>B. If the genus has no valid fraction of species (i.e., K == 0 so p
is undefined), then sample from the emperical distribution of
per-genus fractions.  We&#39;re going to feed data into this by
taxonomic order, so this will come from the per-order distribution.</p>

<pre><code class="r">sim &lt;- function(x, nrep, with.replacement=TRUE, p=1/20) {
  ## First, focus on cases where we have a valid estimate of the
  ## fraction of species that are woody (i.e., at least one known
  ## species).
  ok &lt;- !is.na(x$p)

  w &lt;- matrix(NA, nrow(x), nrep)

  ## A: genera with any known species
  if (with.replacement)
    w[ok,] &lt;- x$W[ok] + rbinom(sum(ok), x$N[ok]-x$K[ok], x$W[ok]/x$K[ok])
  else
    w[ok,] &lt;- t(sapply(which(ok), function(i)
                       rhyper2(nrep, x$H[i], x$W[i], x$N[i])))

  ## B: genera with no known species
  n.unk &lt;- sum(!ok)
  w[!ok,] &lt;- apply(w[ok,,drop=FALSE] / x$N[ok], 2, function(y)
                   rbinom(n.unk, x$N[!ok], quantile(y, runif(n.unk))))

  rownames(w) &lt;- x$genus

  summarise.sim(w, x[c(&quot;order&quot;, &quot;family&quot;, &quot;genus&quot;,
                       &quot;W&quot;, &quot;V&quot;, &quot;H&quot;, &quot;N&quot;, &quot;K&quot;)])
}
</code></pre>

<p>This collects up the results at different taxonomic levels.</p>

<pre><code class="r">summarise &lt;- function(x, p=1/20)
  structure(c(mean(x), quantile(x, c(p/2, 1-p/2))),
            names=c(&quot;mean&quot;, &quot;lower&quot;, &quot;upper&quot;))
summarise.sim &lt;- function(w, info) {
  order &lt;- info$order[[1]]

  info.cols &lt;- c(&quot;W&quot;, &quot;V&quot;, &quot;H&quot;, &quot;N&quot;, &quot;K&quot;)

  ## Genus is easy;
  w.g &lt;- cbind(info, t(apply(w, 1, summarise)))

  ## Family is a pain:
  w.f &lt;- do.call(rbind,
                 lapply(split(as.data.frame(w), info$family), colSums))
  w.f &lt;- t(apply(w.f, 1, summarise))
  w.f &lt;- data.frame(order=order,
                    aggregate(info[info.cols], info[&quot;family&quot;], sum),
                    w.f, stringsAsFactors=TRUE)
  rownames(w.f) &lt;- NULL

  ## Order is easy; we are guaranteed to have just one order here, so:
  w.o &lt;- data.frame(order=order,
                    as.data.frame(t(colSums(info[info.cols]))),
                    t(summarise(colSums(w))), stringsAsFactors=FALSE)

  ret &lt;- list(genus=w.g, family=w.f, order=w.o)
  attr(ret, &quot;total&quot;) &lt;- colSums(w)
  ret
}

rhyper2 &lt;- function(nn, s0, s1, xn, fraction=FALSE) {
  x1 &lt;- seq(s1, xn - s0)
  x0 &lt;- xn - x1
  p1 &lt;- dhyper(s1, x1, x0, s0+s1)
  p1 &lt;- p1 / sum(p1)
  x1[sample(length(p1), nn, TRUE, p1)]
}

do.simulation &lt;- function(dat.g, nrep, with.replacement) {
  f &lt;- function(level) {
    ret &lt;- do.call(rbind, lapply(res, &quot;[[&quot;, level))
    rownames(ret) &lt;- NULL
    ret[c(&quot;p.mean&quot;, &quot;p.lower&quot;, &quot;p.upper&quot;)] &lt;-
      ret[c(&quot;mean&quot;, &quot;lower&quot;, &quot;upper&quot;)] / ret[[&quot;N&quot;]]
    ret
  }

  res &lt;- lapply(split(dat.g, dat.g$order),
                sim, nrep, with.replacement)
  total &lt;- rowSums(sapply(res, attr, &quot;total&quot;))
  overall &lt;- summarise(total)
  overall.p &lt;- overall / sum(dat.g$N)

  list(genus=f(&quot;genus&quot;), family=f(&quot;family&quot;), order=f(&quot;order&quot;),
       overall=overall, overall.p=overall.p, total=total)
}
</code></pre>

<pre><code class="r">set.seed(1)
res.b &lt;- do.simulation(dat.g, 1000, TRUE)  # binomial - with replacement
res.h &lt;- do.simulation(dat.g, 1000, FALSE) # hypergeometric - without
</code></pre>

<p>Repeat this sampling proceedure under a more extreme
classification; all variable species scored as woody:</p>

<pre><code class="r">dat.g.w &lt;- load.woodiness.genus(extreme=&quot;woody&quot;)
res.b.w &lt;- do.simulation(dat.g.w, 1000, TRUE)  # binomial       &amp; woody
res.h.w &lt;- do.simulation(dat.g.w, 1000, FALSE) # hypergeometric &amp; woody
</code></pre>

<p>&hellip;and with all variable species scored as herbaceous:</p>

<pre><code class="r">dat.g.h &lt;- load.woodiness.genus(extreme=&quot;herbaceous&quot;)
res.b.h &lt;- do.simulation(dat.g.h, 1000, TRUE)  # binomial       &amp; herby
res.h.h &lt;- do.simulation(dat.g.h, 1000, FALSE) # hypergeometric &amp; herby
</code></pre>

<h1>Distribution of estimates of woodiness</h1>

<p>This is the raw distribution; i.e., our estimate of the fraction of
species that are woody and its estimate.</p>

<pre><code class="r">fig.distribution.raw &lt;- function(res.b, res.h) {
  n.spp &lt;- sum(res.b$order$N)
  p.b &lt;- res.b$total / n.spp * 100
  p.h &lt;- res.h$total / n.spp * 100

  r &lt;- range(p.b, p.h)
  br &lt;- seq(r[1], r[2], length.out=30)

  h.b &lt;- hist(p.b, br, plot=FALSE)
  h.h &lt;- hist(p.h, br, plot=FALSE)

  xlim &lt;- c(42, 50)
  ylim &lt;- range(h.b$density, h.h$density)

  cols &lt;- cols.methods

  op &lt;- par(mar=c(4.1, 4.1, .5, .5))
  on.exit(par(op))
  plot(h.b, col=cols[1], xlim=xlim, ylim=ylim, freq=FALSE, yaxt=&quot;n&quot;,
       ylab=&quot;&quot;,
       xlab=&quot;Percentage of woody species among all vascular plants&quot;,
       main=&quot;&quot;)
  box(bty=&quot;l&quot;)
  lines(h.h, col=cols[2], freq=FALSE)
  mtext(&quot;Probability density&quot;, 2, line=.5)
}
</code></pre>

<pre><code class="r">fig.distribution.raw(res.b, res.h)
</code></pre>

<p><img src="figure/distribution_raw.png" alt="Distribution of simulated woodiness percentage"/> </p>

<p>Next, expand that plot to include the more extreme estimates
(variable species as woody and variable species as herbaceous).
This shows how much the classification errors affect the analysis.</p>

<pre><code class="r">fig.distribution.raw.errors &lt;- function(res.b,   res.h,
                                        res.b.w, res.h.w,
                                        res.b.h, res.h.h) {
  n.spp &lt;- sum(res.b$order$N)
  res &lt;- list(b  =res.b,   h  =res.h,
              b.w=res.b.w, h.w=res.h.w,
              b.h=res.b.h, h.h=res.h.h)
  p &lt;- lapply(res, function(x) x$total / n.spp * 100)

  r &lt;- range(unlist(p))
  br &lt;- seq(r[1], r[2], length.out=30)

  h &lt;- lapply(p, hist, br, plot=FALSE)

  xlim &lt;- c(42, 50)
  ylim &lt;- range(unlist(lapply(h, function(x) x$density)))

  cols &lt;- cols.methods
  cols.fill &lt;- mix(cols, &quot;white&quot;, 0.5)

  op &lt;- par(mar=c(1.1, 0.5, .5, .5), mfrow=c(2, 1), oma=c(3.1, 2, 0, 0))
  on.exit(par(op))
  plot(NA, xlim=xlim, ylim=ylim, xaxt=&quot;n&quot;, yaxt=&quot;n&quot;, bty=&quot;l&quot;,
       xlab=&quot;&quot;, ylab=&quot;&quot;, main=&quot;&quot;)
  axis(1, labels=FALSE)
  for (i in c(3, 5))
    hist.fill(h[[i]], border=cols[[1]], col=cols.fill[[1]])
  lines(h[[&quot;b&quot;]], col=cols[1], freq=FALSE)
  label(.02, .96, 1)

  plot(NA, xlim=xlim, ylim=ylim, xaxt=&quot;n&quot;, yaxt=&quot;n&quot;, bty=&quot;l&quot;,
       xlab=&quot;&quot;, ylab=&quot;&quot;, main=&quot;&quot;)
  axis(1, labels=TRUE)
  for (i in c(4, 6))
    hist.fill(h[[i]], border=cols[[2]], col=cols.fill[[2]])
  lines(h[[&quot;h&quot;]], col=cols[2], freq=FALSE)
  mtext(&quot;Probability density&quot;, 2, line=.5, outer=TRUE)
  mtext(&quot;Percentage of woody species among all vascular plants&quot;, 1,
        line=2.5, xpd=NA)
  label(.02, .96, 2)
}
</code></pre>

<pre><code class="r">fig.distribution.raw.errors(res.b, res.h, res.b.w, res.h.w, res.b.h, res.h.h)
</code></pre>

<p><img src="figure/distribution_errors.png" alt="Effect of recoding on woodiness estimates"/> </p>

<p>Woodiness is structured among genera and other taxonomic groups.
Make a plot of per genus/family/order estimates of woodiness:</p>

<pre><code class="r">fig.fraction.by.group &lt;- function(res.b, res.h, dat.g, level=&quot;genus&quot;) {
  op &lt;- par(mfrow=c(2, 1), mar=c(2, 2, .5, .5), oma=c(2, 0, 0, 0))
  on.exit(par(op))
  lwd &lt;- 1.5

  n.br &lt;- c(genus=50, family=40, order=30)[[level]]
  tmp &lt;- aggregate(dat.g[c(&quot;W&quot;, &quot;K&quot;)], dat.g[level], sum)
  tmp &lt;- tmp[tmp$K &gt;= 10,] # at least 10 records per group
  h &lt;- hist(100 * tmp$W / tmp$K, n.br, plot=FALSE)

  plot(NA, xlim=c(0, 100), ylim=range(0, h$density),
       xaxt=&quot;n&quot;, yaxt=&quot;n&quot;, bty=&quot;l&quot;, xlab=&quot;&quot;, ylab=&quot;&quot;)
  mtext(&quot;Probability density&quot;, 2, line=.5)
  axis(1, tick=TRUE, label=FALSE)
  label(.02, .96, 1)
  hist.outline(h, col=&quot;black&quot;, lwd=lwd)

  cols &lt;- cols.methods

  x.b &lt;- res.b[[level]]
  x.h &lt;- res.h[[level]]
  h.b &lt;- hist(100*x.b$p.mean[x.b$N &gt;= 10], n=n.br, plot=FALSE)
  h.h &lt;- hist(100*x.h$p.mean[x.h$N &gt;= 10], n=n.br, plot=FALSE)
  ylim &lt;- range(h.b$density, h.h$density)
  plot(NA, xlim=c(0, 100), ylim=ylim,
       xlab=&quot;&quot;, ylab=&quot;&quot;, yaxt=&quot;n&quot;, bty=&quot;n&quot;, bty=&quot;l&quot;)
  mtext(&quot;Probability density&quot;, 2, line=.5)
  mtext(paste(&quot;Percentage of woody species in&quot;, level), 1, outer=TRUE,
        line=.5)

  hist.outline(h.b, col=cols[1], lwd=lwd)
  hist.outline(h.h, col=cols[2], lwd=lwd)

  legend(&quot;topleft&quot;, c(&quot;Strong prior (binomial)&quot;,
                      &quot;Weak prior (hypergeometric)&quot;),
         col=cols, lty=1, bty=&quot;n&quot;, cex=.85, inset=c(.1, 0), lwd=lwd)
  label(.02, .96, 2)
}
</code></pre>

<pre><code class="r">fig.fraction.by.group(res.b, res.h, dat.g, &quot;genus&quot;)
</code></pre>

<p><img src="figure/fraction_by_genus.png" alt="Fraction of woodiness by genus"/> </p>

<pre><code class="r">fig.fraction.by.group(res.b, res.h, dat.g, &quot;family&quot;)
</code></pre>

<p><img src="figure/fraction_by_family.png" alt="Fraction of woodiness by family"/> </p>

<pre><code class="r">fig.fraction.by.group(res.b, res.h, dat.g, &quot;order&quot;)
</code></pre>

<p><img src="figure/fraction_by_order.png" alt="Fraction of woodiness by order"/> </p>

<p>Woodiness also varies over the tree; plot the per-order estimate of
woodiness around the tree (the code to do this is not very pretty,
so is kept separately in <code>R/plot-tree.R</code>)</p>

<pre><code class="r">source(&quot;R/plot-tree.R&quot;)
</code></pre>

<p>Phylogeny at the level of order:</p>

<pre><code class="r">phy.o &lt;- load.phylogeny.order()
</code></pre>

<pre><code class="r">fig.fraction.on.phylogeny(phy.o, res.b)
</code></pre>

<p><img src="figure/fraction_phy_binomial.png" alt="Woodiness percentage by order"/> </p>

<pre><code class="r">fig.fraction.on.phylogeny(phy.o, res.h)
</code></pre>

<p><img src="figure/fraction_phy_hypergeometric.png" alt="Woodiness percentage by order"/> </p>

<h1>Survey:</h1>

<p>Raw results of the survey:</p>

<pre><code class="r">d.survey &lt;- load.survey()
</code></pre>

<p>Convert estimates to normal using logit transformation:</p>

<pre><code class="r">d.survey$Estimate.logit &lt;- boot::logit(d.survey$Estimate / 100)
</code></pre>

<p>Model with training and familiarity as factors:</p>

<pre><code class="r">res &lt;- lm(Estimate.logit ~ Training + Familiarity, d.survey)
summary(res)
</code></pre>

<pre><code>## 
## Call:
## lm(formula = Estimate.logit ~ Training + Familiarity, data = d.survey)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.816 -0.495  0.016  0.607  2.976 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    -1.0674     0.1105   -9.66  &lt; 2e-16 ***
## Training.L      0.3632     0.2305    1.58  0.11634    
## Training.Q      0.0544     0.1733    0.31  0.75397    
## Training.C      0.2069     0.1588    1.30  0.19370    
## Training^4     -0.3203     0.1656   -1.93  0.05415 .  
## Familiarity.L  -1.0419     0.3076   -3.39  0.00081 ***
## Familiarity.Q  -0.2420     0.2109   -1.15  0.25227    
## Familiarity.C  -0.0660     0.1326   -0.50  0.61892    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.982 on 277 degrees of freedom
##   (7 observations deleted due to missingness)
## Multiple R-squared:  0.0656, Adjusted R-squared:  0.042 
## F-statistic: 2.78 on 7 and 277 DF,  p-value: 0.00826
</code></pre>

<pre><code class="r">anova(res)
</code></pre>

<pre><code>## Analysis of Variance Table
## 
## Response: Estimate.logit
##              Df Sum Sq Mean Sq F value Pr(&gt;F)   
## Training      4    5.8    1.46    1.51 0.1990   
## Familiarity   3   12.9    4.32    4.47 0.0044 **
## Residuals   277  267.3    0.97                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
</code></pre>

<p>Regression against |latitude|:</p>

<pre><code class="r">res.lat &lt;- lm(Estimate.logit ~ abs(Lat), d.survey)
anova(res.lat)
</code></pre>

<pre><code>## Analysis of Variance Table
## 
## Response: Estimate.logit
##            Df Sum Sq Mean Sq F value Pr(&gt;F)  
## abs(Lat)    1      5    4.96    5.12  0.024 *
## Residuals 280    271    0.97                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
</code></pre>

<pre><code class="r">summary(res.lat)
</code></pre>

<pre><code>## 
## Call:
## lm(formula = Estimate.logit ~ abs(Lat), data = d.survey)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.854 -0.588  0.124  0.566  3.168 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.65407    0.13105   -4.99  1.1e-06 ***
## abs(Lat)    -0.00804    0.00355   -2.26    0.024 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.985 on 280 degrees of freedom
##   (10 observations deleted due to missingness)
## Multiple R-squared:  0.018,  Adjusted R-squared:  0.0144 
## F-statistic: 5.12 on 1 and 280 DF,  p-value: 0.0244
</code></pre>

<p>Here is the fitted result:</p>

<pre><code class="r">plot(Estimate.logit ~ abs(Lat), d.survey)
abline(res.lat)
</code></pre>

<p><img src="figure/survey_by_latidude.png" alt="Fitted latitude survey regression"/> </p>

<p>As a categorical tropical/non-tropical variable:</p>

<pre><code class="r">res.tro &lt;- lm(Estimate.logit ~ Tropical, d.survey)
anova(res.tro)
</code></pre>

<pre><code>## Analysis of Variance Table
## 
## Response: Estimate.logit
##            Df Sum Sq Mean Sq F value Pr(&gt;F)  
## Tropical    1    5.4    5.39    5.57  0.019 *
## Residuals 280  271.0    0.97                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
</code></pre>

<pre><code class="r">summary(res.tro)
</code></pre>

<pre><code>## 
## Call:
## lm(formula = Estimate.logit ~ Tropical, data = d.survey)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.883 -0.539  0.164  0.606  3.209 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   -1.0116     0.0704  -14.36   &lt;2e-16 ***
## TropicalTRUE   0.2992     0.1268    2.36    0.019 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.984 on 280 degrees of freedom
##   (10 observations deleted due to missingness)
## Multiple R-squared:  0.0195, Adjusted R-squared:  0.016 
## F-statistic: 5.57 on 1 and 280 DF,  p-value: 0.019
</code></pre>

<p>Distribution of estimates vs different levels of botanical
familiarity and education, with the estimates from the database
overlaid.</p>

<pre><code class="r">fig.survey.results &lt;- function(d.survey, res.b, res.h) {
  ci &lt;- 100*cbind(res.b$overall.p, res.h$overall.p)
  cols &lt;- cols.methods
  cols.tr &lt;- diversitree:::add.alpha(cols, .5)

  op &lt;- par(no.readonly=TRUE)
  on.exit(par(op))

  layout(rbind(1:2), widths=c(4, 5))
  par(mar=c(6.5, 2, .5, .5), oma=c(0, 2, 0, 0))
  plot(Estimate ~ Familiarity, d.survey, col=cols.shading, axes=FALSE,
       xlab=&quot;&quot;, ylab=&quot;&quot;, bty=&quot;l&quot;,
       ylim=c(0, 100))
  axis(2, las=1)
  text(1:4, -5, levels(d.survey$Familiarity),
       srt=-55, xpd=NA, adj=c(0, NA), cex=.85)
  mtext(&quot;Estimate of percentage woodiness&quot;, 2, line=2.75)
  label(.02, .96, 1)

  usr &lt;- par(&quot;usr&quot;)
  rect(usr[1], ci[&quot;lower&quot;,], usr[2], ci[&quot;upper&quot;,], col=cols.tr,
       border=NA)
  abline(h=ci[&quot;mean&quot;,], col=cols)

  plot(Estimate ~ Training, d.survey, col=cols.shading, axes=FALSE,
       xlab=&quot;&quot;, ylab=&quot;&quot;, bty=&quot;l&quot;, ylim=c(0, 100))
  axis(2, las=1)
  xl &lt;- c(&quot;Postgrad&quot;,&quot;Part postgrad&quot;,&quot;Undergrad&quot;,&quot;Part undergrad&quot;, &quot;None&quot;)
  text(1:5, -5, xl,
       srt=-55, xpd=TRUE, adj=c(0, NA), cex=.85) 
  label(.02, .96, 2) 

  usr &lt;- par(&quot;usr&quot;)
  rect(usr[1], ci[&quot;lower&quot;,], usr[2], ci[&quot;upper&quot;,], col=cols.tr,
       border=NA)
  abline(h=ci[&quot;mean&quot;,], col=cols)
}
</code></pre>

<pre><code class="r">fig.survey.results(d.survey, res.b, res.h)
</code></pre>

<p><img src="figure/survey_results.png" alt="Survey results by predictor"/> </p>

<p>And the raw distribution of survey results, showing the general
tendency for relatively low estimates, again overlaid with the
estimates from the database:</p>

<pre><code class="r">fig.survey.distribution &lt;- function(d.survey, res.b, res.h) {
  op &lt;- par(mfrow=c(2, 1), mar=c(2, 4, .5, .5), oma=c(2, 0, 0, 0))
  on.exit(par(op))
  lwd &lt;- 1.5

  ci &lt;- 100*cbind(res.b$overall.p, res.h$overall.p)
  hist(d.survey$Estimate, xlim=c(0, 100), las=1, col=cols.shading,
       xaxt=&quot;n&quot;, xlab=&quot;&quot;, ylab=&quot;Number of responses&quot;, main=&quot;&quot;)
  box(bty=&quot;l&quot;)
  axis(1, label=FALSE)
  label(.02, .96, 1)

  usr &lt;- par(&quot;usr&quot;)
  rect(ci[&quot;lower&quot;,], usr[3], ci[&quot;upper&quot;,], usr[4],
       col=diversitree:::add.alpha(cols.methods, .5), border=NA)
  abline(v=ci[&quot;mean&quot;,], col=cols.methods)

  h.tropical &lt;- hist(d.survey$Estimate[d.survey$Tropical], plot=FALSE)
  h.temperate &lt;- hist(d.survey$Estimate[!d.survey$Tropical], plot=FALSE)

  ylim &lt;- range(h.tropical$counts, h.temperate$counts)
  plot(NA, xlim=c(0, 100), ylim=ylim, las=1, xlab=&quot;&quot;,
       ylab=&quot;Number of responses&quot;, bty=&quot;n&quot;, bty=&quot;l&quot;)
  mtext(&quot;Estimate of percentage woodiness&quot;, 1, outer=TRUE, line=.5)

  hist.outline(h.tropical,  col=cols.tropical[1], lwd=lwd, density=FALSE)
  hist.outline(h.temperate, col=cols.tropical[2], lwd=lwd, density=FALSE)

  usr &lt;- par(&quot;usr&quot;)
  rect(ci[&quot;lower&quot;,], usr[3], ci[&quot;upper&quot;,], usr[4],
       col=diversitree:::add.alpha(cols.methods, .5), border=NA)
  abline(v=ci[&quot;mean&quot;,], col=cols.methods)

  label(.02, .96, 2)

  legend(&quot;topright&quot;, c(&quot;Tropical&quot;, &quot;Temperate&quot;), lwd=lwd,
         col=cols.tropical, bty=&quot;n&quot;, cex=.75)
}
</code></pre>

<pre><code class="r">fig.survey.distribution(d.survey, res.b, res.h)
</code></pre>

<p><img src="figure/survey_distribution.png" alt="Distribution of survey results"/> </p>

<h1>Variability of a genus vs size</h1>

<p>These plots look at the how variable a genus is vs its size (left
column) or the number of species in a known state (right column).
The top row looks at how variable the genus is (a single type or a
mixed type), the middle row at the probability that a genus is
varaible.  The bottom row looks at the proportion of species that
are woody in a genus vs its size, testing if woody genera are
relatively larg or relatively small (woody genera are relatively
smaller).</p>

<pre><code class="r">fig.variability &lt;- function(dat.g) {
  dat.g$p.rare &lt;- (0.5 - abs(dat.g$p - 1/2)) * 2
  dat.g$variable &lt;- dat.g$p.rare &gt; 0

  sub &lt;- dat.g[!is.nan(dat.g$p),]

  ## Breaks for the moving average:
  br.N &lt;- log.seq.range(sub$N, 20)
  br.K &lt;- log.seq.range(sub$K, 15)

  ## Classify points:
  i.N &lt;- findInterval(sub$N, br.N, all.inside=TRUE)  
  i.K &lt;- findInterval(sub$K, br.K, all.inside=TRUE)  

  ## Midpoints for plotting.
  mid.N &lt;- (br.N[-1] + br.N[-length(br.N)])/2
  mid.K &lt;- (br.K[-1] + br.K[-length(br.K)])/2

  m.N &lt;- tapply(sub$p.rare, i.N, mean)
  m.K &lt;- tapply(sub$p.rare, i.K, mean)
  p.N &lt;- tapply(sub$variable, i.N, mean)
  p.K &lt;- tapply(sub$variable, i.K, mean)
  f.N &lt;- tapply(sub$p, i.N, mean)
  f.K &lt;- tapply(sub$p, i.K, mean)

  pch &lt;- 19
  cex &lt;- 0.5
  col &lt;- &quot;#00000066&quot;

  op &lt;- par(oma=c(4.1, 4.1, 0, 0),
            mar=c(1.1, 1.1, .5, .5),
            mfrow=c(3, 2))

  plot(p.rare ~ N, sub, pch=pch, cex=cex, col=col, log=&quot;x&quot;,
       axes=FALSE)
  lines(m.N ~ mid.N, col=&quot;red&quot;)
  axis(1, labels=FALSE) 
  axis(2, c(0, 1), c(&quot;Single type&quot;, &quot;50:50&quot;), las=1)
  mtext(&quot;Variability&quot;, 2, 3)
  box(bty=&quot;l&quot;)
  label(.02, .96, 1)

  plot(p.rare ~ K, sub, pch=pch, cex=cex, col=col, log=&quot;x&quot;,
       axes=FALSE)
  lines(m.K ~ mid.K, col=&quot;red&quot;)
  axis(1, labels=FALSE) 
  axis(2, c(0, 1), labels=FALSE)
  box(bty=&quot;l&quot;)
  label(.02, .96, 2)

  plot(variable ~ N, sub, pch=pch, cex=cex, col=col, log=&quot;x&quot;,
       bty=&quot;l&quot;, las=1, axes=FALSE)
  lines(p.N ~ mid.N, col=&quot;red&quot;)
  axis(1, labels=FALSE)
  axis(2, las=1)
  mtext(&quot;Probability genus is variable&quot;, 2, 3) 
  box(bty=&quot;l&quot;) 
  label(.02, .96, 3)

  plot(variable ~ K, sub, pch=pch, cex=cex, col=col, log=&quot;x&quot;,
       bty=&quot;l&quot;, yaxt=&quot;n&quot;, las=1, axes=FALSE)
  lines(p.K ~ mid.K, col=&quot;red&quot;)
  axis(1, labels=FALSE)
  axis(2, labels=FALSE) 
  box(bty=&quot;l&quot;) 
  label(.02, .96, 4)

  plot(p ~ N, sub, pch=pch, cex=cex, col=col, log=&quot;x&quot;,
       bty=&quot;l&quot;, las=1)
  lines(f.N ~ mid.N, col=&quot;red&quot;)
  mtext(&quot;Number of species in genus&quot;, 1, 3)
  mtext(&quot;Proportion of species woody&quot;, 2, 3)
  label(.02, .96, 5)

  plot(p ~ K, sub, pch=pch, cex=cex, col=col, log=&quot;x&quot;,
       bty=&quot;l&quot;, yaxt=&quot;n&quot;, las=1)
  lines(f.K ~ mid.K, col=&quot;red&quot;)
  axis(2, labels=FALSE)
  mtext(&quot;Number of species with known state&quot;, 1, 3)
  label(.02, .96, 6)
}
</code></pre>

<pre><code class="r">fig.variability(dat.g)
</code></pre>

<p><img src="figure/variability.png" alt="Variability by genus size"/> </p>

<h1>Write out partly processed data sets</h1>

<p>To save having to rerun everything, these are the estimates by
genus, family and order for the two different sampling approaches
and the three different treatment of variable species (so 3 x 2 x 3
= 18 files)</p>

<pre><code class="r">write.output &lt;- function(d, type) {
  for (tax in c(&quot;genus&quot;, &quot;family&quot;, &quot;order&quot;))
    write.csv(d[[tax]],
              file.path(&quot;output/results&quot;, sprintf(&quot;%s-%s.csv&quot;, tax, type)),
              row.names=FALSE)
}
</code></pre>

<p>Core data sets:</p>

<pre><code class="r">dir.create(&quot;output/results&quot;, FALSE)
write.output(res.b, &quot;binomial-strong-prior&quot;)
write.output(res.h, &quot;hypergeometric-weak-prior&quot;)
</code></pre>

<p>Extra data sets:</p>

<pre><code class="r">write.output(res.b.w, &quot;binomial-strong-prior-wood-biased&quot;)
write.output(res.h.w, &quot;hypergeometric-weak-prior-wood-biased&quot;)
write.output(res.b.h, &quot;binomial-strong-prior-herb-biased&quot;)
write.output(res.h.h, &quot;hypergeometric-weak-prior-herb-biased&quot;)
</code></pre>

<p>Meta data for interpreting these files.</p>

<pre><code class="r">metadata &lt;- 
  list(order=&quot;Taxonomic order&quot;,
       family=&quot;Taxonomic family&quot;,
       genus=&quot;Taxonomic genus&quot;,
       W=&quot;Number of species known to be woody&quot;,
       V=&quot;Number of species known to be variable&quot;,
       H=&quot;Number of species known to be herbaceous&quot;,
       N=&quot;Estimate of the number of species in the genus/family/order&quot;,
       K=&quot;Number of species with known state (W + H)&quot;,
       mean=&quot;Mean estimated number of woody species&quot;,
       lower=&quot;0.025 quantile of estimated number of woody species&quot;,
       upper=&quot;0.975 quantile of estimated number of woody species&quot;,
       p.mean=&quot;Mean estimated fration of woody species&quot;,
       p.lower=&quot;0.025 quantile of estimated fraction of woody species&quot;,
       p.upper=&quot;0.975 quantile of estimated fraction of woody species&quot;)
metadata &lt;- data.frame(column=names(metadata),
                       description=unlist(metadata),
                       stringsAsFactors=FALSE)
write.csv(metadata, &quot;output/results/metadata.csv&quot;, row.names=FALSE)
</code></pre>

<h1>Graphical abstract:</h1>

<pre><code class="r">fig.graphical.abstract &lt;- function(res.b, res.h, dat.g, d.survey) {
  p.raw &lt;- sum(dat.g$W) / sum(dat.g$K)
  p.survey &lt;- mean(d.survey$Estimate) / 100
  p.data &lt;- mean(c(res.b$overall.p[[&quot;mean&quot;]], res.h$overall.p[[&quot;mean&quot;]]))

  f &lt;- function(p, title) {
    pie(c(p, 1-p), c(&quot;Woody&quot;, &quot;Herbaceous&quot;), col=cols.woody)
    text(0, par(&quot;usr&quot;)[2], title, adj=c(0.5, 0), cex=1.2)
  }
  par(mfrow=c(1, 3), mar=rep(1, 4))
  f(p.raw,    &quot;Raw data&quot;)
  f(p.survey, &quot;Survey estimate&quot;)
  text(0, 1.5, &quot;How much of the world is woody?&quot;, cex=1.5, xpd=NA)
  f(p.data,   &quot;Bias corrected&quot;)
}
</code></pre>

<pre><code class="r">fig.graphical.abstract(res.b, res.h, dat.g, d.survey)
</code></pre>

<p><img src="figure/graphical_abstract.png" alt="plot of chunk graphical_abstract"/> </p>

<h1>Produce PDF versions of figures for publication:</h1>

<pre><code class="r">if (!interactive()) {
  to.pdf(&quot;doc/figs/fraction-by-genus.pdf&quot;, 6, 6,
         fig.fraction.by.group(res.b, res.h, dat.g, &quot;genus&quot;))
  to.pdf(&quot;doc/figs/fraction-by-family.pdf&quot;, 6, 6,
         fig.fraction.by.group(res.b, res.h, dat.g, &quot;family&quot;))
  to.pdf(&quot;doc/figs/fraction-by-order.pdf&quot;, 6, 6,
         fig.fraction.by.group(res.b, res.h, dat.g, &quot;order&quot;))

  to.pdf(&quot;doc/figs/fraction-on-phylogeny.pdf&quot;, 6, 6,
         fig.fraction.on.phylogeny(phy.o, res.b))

  to.pdf(&quot;doc/figs/fraction-on-phylogeny-supp.pdf&quot;, 6, 6,
         fig.fraction.on.phylogeny(phy.o, res.h))

  to.pdf(&quot;doc/figs/distribution-raw.pdf&quot;, 6, 4,
         fig.distribution.raw(res.b, res.h))
  to.pdf(&quot;doc/figs/distribution-raw-errors.pdf&quot;, 6, 4,
         fig.distribution.raw.errors(res.b, res.h, res.b.w, res.h.w,
                                     res.b.h, res.h.h))

  to.pdf(&quot;doc/figs/survey-results.pdf&quot;, 6, 4,
         fig.survey.results(d.survey, res.b, res.h))

  to.pdf(&quot;doc/figs/survey-distribution.pdf&quot;, 6, 5,
         fig.survey.distribution(d.survey, res.b, res.h))

  to.pdf(&quot;doc/figs/variability.pdf&quot;, 7, 8,
         fig.variability(dat.g))

  to.pdf(&quot;doc/figs/graphical-abstract.pdf&quot;, 7, 3.5,
         fig.graphical.abstract(res.b, res.h, dat.g, d.survey))
}
</code></pre>

<pre><code>## Creating doc/figs/fraction-by-genus.pdf
</code></pre>

<pre><code>## Creating doc/figs/fraction-by-family.pdf
</code></pre>

<pre><code>## Creating doc/figs/fraction-by-order.pdf
</code></pre>

<pre><code>## Creating doc/figs/fraction-on-phylogeny.pdf
</code></pre>

<pre><code>## Creating doc/figs/fraction-on-phylogeny-supp.pdf
</code></pre>

<pre><code>## Creating doc/figs/distribution-raw.pdf
</code></pre>

<pre><code>## Creating doc/figs/distribution-raw-errors.pdf
</code></pre>

<pre><code>## Creating doc/figs/survey-results.pdf
</code></pre>

<pre><code>## Creating doc/figs/survey-distribution.pdf
</code></pre>

<pre><code>## Creating doc/figs/variability.pdf
</code></pre>

<pre><code>## Creating doc/figs/graphical-abstract.pdf
</code></pre>

<h1>Version information:</h1>

<pre><code class="r">sessionInfo()
</code></pre>

<pre><code>## R version 3.1.0 (2014-04-10)
## Platform: x86_64-pc-linux-gnu (64-bit)
## 
## locale:
##  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
##  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
##  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
##  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            
## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] diversitree_0.9-7 Rcpp_0.11.1       subplex_1.1-3     ape_3.1-2        
## [5] deSolve_1.10-8    knitr_1.6        
## 
## loaded via a namespace (and not attached):
##  [1] boot_1.3-11     codetools_0.2-8 digest_0.6.4    evaluate_0.5.5 
##  [5] formatR_0.10    grid_3.1.0      lattice_0.20-29 nlme_3.1-117   
##  [9] stringr_0.6.2   tools_3.1.0
</code></pre>

    </div>
  </div>
</body>

</html>
